





# 面试题1

1. 来源企业面试汇总，高阶面试题
2. 

## 要求

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612853410447-fd8a67c2-8a2f-4387-87d7-70a9addcc2a3.png?x-oss-process=image%2Fresize%2Cw_2080)



## java体系

### 集合

![image.png](https://cdn.nlark.com/yuque/0/2021/png/8398487/1612682246764-b968d90e-3e26-4c86-a481-1c49ebfc0503.png)

### java 锁

![image.png](https://cdn.nlark.com/yuque/0/2021/png/8398487/1612752395997-fa69934f-6482-42a6-88a4-732b24bbea76.png?x-oss-process=image%2Fresize%2Cw_1040)



- [3]多线程如何进行线程同步

- [2]线程池的执行与线程分配要求

```
首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。
如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务。
如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。
如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。
如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。
```

![img](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612867985813-fec0985c-e4ae-4a22-9f37-feb42738e224.png)

- [2]多线性如何保证顺序执行
- Java线程执行过程中有几种状态？

   **A:** 新建、就绪、运行、死亡(两种)、堵塞(sleep、wait-notify、suspend → resume)。

- [3]**Q:**锁池状态介绍？

   **A:****（**Java 主流锁 **）**见下图:图2

1. 当前线程想调用对象A的同步方法时，发现对象A的锁被别的线程占有，此时当前线程进入锁池状态。简言之，锁池里面放的都是想争夺对象锁的线程。 
2. 当一个线程1被另外一个线程2唤醒时，1线程进入锁池状态，去争夺对象锁。

1. 锁池是在同步的环境下才有的概念，一个对象对应一个锁池。

*在线参考：* [*https://www.cnblogs.com/hejing-swust/p/8038263.html*](https://www.cnblogs.com/hejing-swust/p/8038263.html)



### execute和submit的区别？

- 接收的参数不一样  

- execute方法位于接口Executor中**：**void execute(Runnable command);
- submit方法位于AbstractExecutorService中:

- submit有返回值，而execute没有
- submit方便Exception处理

```java
1     public Future<?> submit(Runnable task) {
 2         if (task == null) throw new NullPointerException();
 3         RunnableFuture<Void> ftask = newTaskFor(task, null);
 4         execute(ftask);
 5         return ftask;
 6     }
 7 
 8     public <T> Future<T> submit(Runnable task, T result) {
 9         if (task == null) throw new NullPointerException();
10         RunnableFuture<T> ftask = newTaskFor(task, result);
11         execute(ftask);
12         return ftask;
13     }
14 
15     public <T> Future<T> submit(Callable<T> task) {
16         if (task == null) throw new NullPointerException();
17         RunnableFuture<T> ftask = newTaskFor(task);
18         execute(ftask);
19         return ftask;
20     }
```

总结：submit最终也是在调用execute方法，无论是Runnable还是Callable类型接口，都会被封装成FutureTask。

如果使用submit方法提交，会进一步封装成FutureTask，执行execute方法，在FutureTask里面重写的run方法里面调用Callable接口的call方法。

### [3]设计一个高并发的单例模式(指令重排)

```java
public class Singleton {
    private volatile static Singleton uniqueInstance;
    private Singleton() {
    }
    public  static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

### [2]如何避免类里面的字段被序列化

```
transient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。transient 只能修饰变量，不能修饰类和方法。
```

### [1]volatile 是什么，解决了什么问题

```
禁止编译器优化而重排序指令。
对 volatile 修饰的变量值，保证线程读取到的值是最新的，而不是寄存器中缓存的值。
编译器会自作主张的对代码顺序优化，但是在多线程环境下可能导致不一致的问题。

volatile 修饰的变量，进行写操作时，这个变量将会被直接写入共享内存，而不是线程中缓存。volatile 变量读操作时，直接从共享内存中读，而不是从线程的缓存中读取，保证线程每次读到的都是最新值。也就是保证了内存可见性。
```



# 中间件

##   Redis

- [4]Bitmaps 是什么，在什么场景用过

- [2]Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？
- [1]Redis 有多少个库

- [5]Redis的线程模型，5.0  6.0区别，如何保证多线程竞争

- [3]Redis 集群的 key 是如何寻址的？分布式寻址都有哪些算法
- [2]什么是 redis 的雪崩、穿透和击穿？如何解决

- [2]redis 过期策略、多Key如何操作  rdb aof



- 使用redis的场景、数据结构适用的场景？

​    **A：**![img](https://cdn.nlark.com/yuque/0/2021/png/8398487/1612924101097-34aa724c-93fd-4625-ac7c-597f4e9213ff.png)

- [2] **Q：** Redis 比 map/guava 的优点？

​    **A：**性能、容量、分布式缓存。

- [4]**Q：**使用redis有哪些缺点？(扩容、数据一致性)

   **A：**内存数据，消耗内存；设置过期策略

  单线程

  线上扩容[加分项]

- [2]  **Q：**穿透的场景及解决方案？(个人思考)

**A：**

1. 原因： 缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉
2. 解决方案：

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击

1. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

- [3]  **Q：**雪崩的场景及解决方案？(个人思考)

**A：**

1. 原因： 缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
2. 解决方案：

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。

1. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。

- [3]  **Q：**redis如何做内存优化？

**A：**可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面

- [4] **Q：**竞争key产生的原因，怎么解决？

​    **A：**

1. 原因：多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！
2. 解决方案：分布式锁(zookeeper / redis)。

1. 解决思路：*每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。*

- [5]**Q：** Redis事务？

   **A：**

1. **概念：** redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。
2. **阶段：**

1. 事务开始
2. 命令入队

1. 事务执行； 事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排。

1. **事务隔离****：**单进程程序，执行事务时不会中断；自带隔离熟悉。
2. **事务回滚****：**单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

1. 其他事项方式：

1. 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完。
2. 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐。



*在线参考文献：*[*https://www.cnblogs.com/javazhiyin/p/13839357.html*](https://www.cnblogs.com/javazhiyin/p/13839357.html)



## MQ

- [5]消息队列满了以后该怎么处理？有几百万消息持续积压几小时，解决方案？

- [2]Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？
- [2]如何保证幂等性

- [2]如何处理消息丢失的问题
- [2]如何保证消息的顺序性？

- [2]如何解决消息队列的延时以及过期失效问题？

### 使用MQ，出现重复消费的原因及解决方式？

1. 原因：

1. 生产者生产重复的业务消息
2. 消费标记混乱导致

1. 解决方案： 

1. 生产方：业务消息增加唯一ID.
2. 消费方：验证业务消息唯一ID.





## 框架与源码

- [2]描述Spring MVC的工作流程-mvc原理：  halderMapping》handlerAdapter》viewResolver》modelAndView》返回页面内容渲染

![img](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612865346095-2306f980-e54b-422d-9d56-5ea986885928.png)

- [1]SpringBoot 研发常用涉及的注解

```
@RestController  @RequestMapping @Configuration 
@ResponseBody @Component @AutoWired 
@RequestParam  @PathVariable  @ComponentScan
```

- [1]SpringCloud 研发常用涉及的注解

```java
@EnableHystrix  @EnableAutoConfiguration @Import @ImportResource @FeignClient @CrossOrigin  @RefreshScope @EnableFeignClients @EnableCircuitBreaker
```

- [3]如何封装自己的Starter

```
https://juejin.cn/post/6844903827519307784
```

- [2]SpringBoot通过哪里加载的配置文件 SPI

```
META-INF spring.factories
```

### [2]SpringBoot yml properties 加载顺序

```
1.命令行参数
所有的配置都可以在命令行上进行指定，多个配置用空格分开； --配置项=值
java -jar spring-boot-0.0.1-SNAPSHOT.jar --server.port=8081 --server.context-path=/abc
2.来自java:comp/env的JNDI属性
3.Java系统属性（System.getProperties()）
4.操作系统环境变量
5.RandomValuePropertySource配置的random.*属性值
6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件
7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件
8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件
9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件
10.@Configuration注解类上的@PropertySource
11.通过SpringApplication.setDefaultProperties指定的默认属性
```

- ### [2]Eureka和Nacos差异

| 模块     | Nacos | Eureka | 说明                                                         |
| -------- | ----- | ------ | ------------------------------------------------------------ |
| 注册中心 | 是    | 是     | 服务治理基本功能，负责服务中心化注册                         |
| 配置中心 | 是    | `否`   | Eureka需要配合Config实现配置中心，且不提供管理界面           |
| 动态刷新 | 是    | `否`   | Eureka需要配合MQ实现配置动态刷新，Nacos采用Netty保持TCP长连接实时推送 |
| 可用区AZ | 是    | 是     | 对服务集群划分不同区域，实现区域隔离，并提供容灾自动切换     |
| 分组     | 是    | `否`   | Nacos可用根据业务和环境进行分组管理                          |
| 元数据   | 是    | 是     | 提供服务标签数据，例如环境或服务标识                         |
| 权重     | 是    | `否`   | Nacos默认提供权重设置功能，调整承载流量压力                  |
| 健康检查 | 是    | 是     | Nacos支持由客户端或服务端发起的健康检查，Eureka是由客户端发起心跳 |
| 负载均衡 | 是    | 是     | 均提供负责均衡策略，Eureka采用Ribion                         |

- [3]Ribbon有哪些负载算法  7种

```
RoundRobinRule(轮询算法)

RandomRule(随机算法)

AvailabilityFilteringRule()：会先过滤由于多次访问故障而处于断路器跳闸状态的服务，还有并发的连接数量超过阈值的服务，然后对剩余的服务列表按照轮询策略进行访问

WeightedResponseTimeRule()：根据平均响应的时间计算所有服务的权重，响应时间越快服务权重越大被选中的概率越高，刚启动时如果统计信息不足，则使用RoundRobinRule策略，等统计信息足够会切换到WeightedResponseTimeRule

RetryRule()：先按照RoundRobinRule的策略获取服务，如果获取失败则在制定时间内进行重试，获取可用的服务。

BestAviableRule()：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务

ZoneAvoidanceRule()：默认规则，符合判断server所在区域的性能和server的可用性选择服务器
```

- [2]如何自定义负载均衡算法





- ### 简述Spring Bean的生命周期

![img](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612866875704-bdda7201-f2a4-4046-9418-bb4493111ca8.png)

- [2]Spring如何解决循环依赖

![img](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612866917857-1c6d1bc2-eb8e-4887-9109-466f223ebc83.png)

- [2]聊一聊Spring的扩展点

![img](https://cdn.nlark.com/yuque/0/2021/png/12568213/1612866954903-1fca1276-6861-4d68-a90e-5135247b2752.png)

- [1]JDK动态代理和CGLIB动态代理的区别

```
jdk动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用业务方法前调用InvocationHandler处理。代理类必须实现InvocationHandler接口

cglib是针对类来实现代理的，它会对目标类产生一个代理子类，通过方法拦截技术对过滤父类的方法调用。代理子类需要实现MethodInterceptor接口
```



### spring cloud 常用的组件？

**A：**

- Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；
- Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；

- Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；
- Feign：基于Ribbon和Hystrix的声明式服务调用组件；

- Zuul：[API网关](https://cloud.tencent.com/product/apigateway?from=10680)组件，对请求提供路由及过滤功能。

- [3]  **Q：**Spring Cloud 和dubbo区别?

**A：**

1. 服务调用方式 dubbo是RPC springcloud Rest Api
2. 注册中心,dubbo 是zookeeper springcloud是eureka，也可以是zookeeper

1. 服务网关,dubbo本身没有实现，只能通过其他第三方技术整合，springcloud有Zuul路由网关，作为路由服务器，进行消费者的请求分发,springcloud支持断路器，与git完美集成配置文件支持版本控制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。

- [5]  **Q：**微服务框架的缺点或者劣势(分布式事务、维护成本)？

**A：**

1. 缺点：

1.  运维成本、微服务治理成本、系统维护升级；
2. 分布式系统开发的技术成本高（容错、分布式事物等）

1. 分布式事务：(分布式事务就是为了保证不同数据库的数据一致性)

1. **事务特性：**ACID； 原子性、一致性、隔离性、持久性；
2. **分布式系统：****CAP原****则****；** 一致性、可用性、容错性；

1. 解决方案：

1. 两端提交/XA

1. 第一阶段：协调各个本地资源管理器的事务管理器
2. 提交事务，如果其中任意一个资源的回复是 no, 则回滚事务。

1. 存在问题： 同步阻塞、单点故障(系统不可用)、数据一致性保障率低(网络、宕机)。

1. TCC：

1. Try阶段 尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）
2. Confirm 阶段 确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。

1. Cancel 取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。
2. 解决问题：

1.  同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。
2.  数据一致性：补偿机制，业务活动管理器控制一致性

1.  引入集群：解决了协调者单点，由主业务方发起并完成这个业务活动。

- [2]  **Q：**SpringBoot和SpringCloud的区别？

**A：** SpringBoot专注于快速方便的开发单个个体微服务。

SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合     并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、     全局锁、决策竞选、分布式会话等等集成服务。

SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于     依赖的关系。

SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。

### Q：什么是Spring Cloud Gateway?

**A：**Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul网关。网关作为流量          的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。

使用了一个RouteLocatorBuilder的bean去创建路由，除了创建路由RouteLocatorBuilder可以让你添加各种predicates和filters，predicates断言的意思，顾名思义就是根据具体的请求的规则，由具体的route去处理，filters是各种过滤器，用来对请求做各种判断和修改。

- [5] **Q：** TCP粘包产生的原因，怎么解决？

**A：**数据读取边界错误所致。

*多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发生方的发送边界，而采用某一估测值大小来进行数据读出，若双方的size不一致时就会使数据包的边界发生错位，导致读出错误的数据分包。*

解决：

1. 定长发送

1. 此方案适在发送数据包长度较为稳定(趋于某一固定值)的情况下有较好的效果。

1. 尾部标记序列

1. 接收方需要对数据进行分析，甄别尾部序列。
2. 尾部序列的确定本身是一个问题。什么样的序列可以向”\0”一样来做一个结束符呢？这个序列必须是不具备通常任何人类或者程序可识别的带含义的数据序列，就像“\0”是一个无效字符串内容，因而可以作为字符串的结束标记。

1. 头部标记分步接收

1. 需要多封装sizeof(_data_head)的数据，积累效应也不可完全忽略
2. 接收方的接收动作分成了两次，也就是进行数据读取的操作被增加了一倍，而数据读取操作的recv或者read都是系统调用，这对内核而言的开销是一个不能完全忽略的影响，对程序而言性能影响可忽略

- 

[*https://cloud.tencent.com/developer/article/1612378*](https://cloud.tencent.com/developer/article/1612378)

## 数据库：

- 行级锁、表级锁、页级锁、间隙锁
- [4]分库分表所带来的问题、如何解决

- [3]分库分表有哪些拆分方式？如何选择？（业务）
- [2]简述分库分表

## JVM 



- 介绍下完整GC流程、知道几种垃圾回收器并介绍下？

   **A：**

1. 现在有一个新对象产生，那么对象一定需要内存空间，于是现在需要为该对象进行内存空间的申请。
2. 首先会判断伊甸园区是否有内存空间，如果此时有充足内存空间，则直接将新对象保存到伊甸园区。

1. 但是如果此时伊甸园区的内存空间不足，那么会自动执行Minor GC操作，将伊甸园区无用的内存空间进行清理。清理之后会继续判断伊甸园区空间是否充足？如果充足，则将新的对象直接在伊甸园区进行内存空间分配。
2. 如果执行Minor GC之后伊甸园区空间依然不足，那么这个时候会进行存活区判断，如果存活区有剩余空间，则将伊甸园区的部分活跃对象保存在存活区，随后继续判断伊甸园区的内存空间是否充足，如果充足，则进行内存空间分配。

1. 如果此时存活区也没有内存空间了，则继续判断老年区，如果此时老年区的空间充足，则将存活区中的活跃对象保存到老年区，而后存活区应付出现空余空间，随后伊甸园区将部分活跃对象保存地存活区中，最后在伊甸园区为新对象分配内存空间。
2. 如果这个时候老年代内存空间也满了，那么这个时候将产生Major GC（Full GC）。然后再将存活区中的活跃对象保存到老年区，从而腾出空间，然后再将伊甸园区的部分活跃对象保存到存活区，最后在伊甸园区为新对象分配内存空间。

1. 如果老年代执行Full GC之后依然空间依然不足，应付产生OOM（OutOfMemoryError）异常。

*在线参考：*[*https://blog.csdn.net/qq_34560242/article/details/81020452*](https://blog.csdn.net/qq_34560242/article/details/81020452)

![img](https://cdn.nlark.com/yuque/0/2021/png/8398487/1612842090102-2e61dd46-f7b3-4edb-806a-1071dcb0b7a6.png)



- [3]**Q:**G1和CMS的区别，分别适用于哪些场景？

   **A：**

**CMS：**以获取最短回收停顿时间为目标的收集器，基于并发“标记清理”实现

1. 初始标记：独占PUC，仅标记GCroots能直接关联的对象
2. 并发标记：可以和用户线程并行执行，标记所有可达对象

1. 重新标记：独占CPU(STW)，对并发标记阶段用户线程运行产生的垃圾对象进行标记修正
2. 并发清理：可以和用户线程并行执行，清理垃圾

优点：并发，低停顿

缺点：

1. 占用CPU、程序变慢卡顿；
2. 标记后无法处理新生垃圾，需等待下次GC;

1. 标记清理 会产生大量碎片消耗很大内存空间(触发FullGC)。**回到缺点1**。

**G1：**面向服务端应用的垃圾收集器。

1. **并行与并发：**G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-the-world停顿的时间，部分其他收集器原来需要停顿Java线程执行的GC操作，G1收集器仍然可以通过并发的方式让Java程序继续运行。
2. 分代收集

1. 空间整合 与CMS的标记-清除算法不同，G1从整体来看是基于**标记-整理算法**实现的收集器，从局部（两个Region之间）上来看是基于“**复制**”算法实现的。但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。**这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC**。
2. 可预测的停顿

![img](https://cdn.nlark.com/yuque/0/2021/png/8398487/1612843277793-1aa0ecc9-f658-4777-8e72-37abbf8a81a5.png)

*在线参考：* [*https://juejin.cn/post/6844903974676463629*](https://juejin.cn/post/6844903974676463629)



- [2] **Q：**引用类型有几种, GC与引用类型的关系？

​    **A：**

1. 强引用【类似于Object obj=new Object()】只要强引用存在垃圾收集器永远不会回收掉被引用的对象
2. 软引用【实现方法SoftReference】，只有在垃圾回收内存空间不足时才会回收这类引用指向的对象，多用在缓存对象中

1. 弱引用【实现方法WeakReference】，只要发生垃圾回收就会被回收
2. 虚引用【实现方法PhantomReference】，是引用关系最弱的一种，无法通过虚引用来虚的一个对象实例



# 算法

# 基础算法

1. [1] **Q：**递归一个数， 是否为 2 的整次幂？

**A：num % 2**

1. [2] 原地排序找出一个数组中重复的元素？

```
[1,5,6,8,1,6,3,7]
for (int i = 0; i < nums.length; i++) {
    int n = nums[i];
    //try
    if (n == nums[n] && n != i) return n;
    //swap
    int tmp = nums[i];
    nums[i] = nums[n];
    nums[n] = tmp;
}
```

1. [3]**Q：**两个数字字符串在求和？

   **A：**

1. 反转两个字符串，便于从低位到高位相加和最高位的进位导致和的位数增加；
2. 对齐两个字符串，即短字符串的高位用‘0’补齐，便于后面的相加；

1. 把两个正整数相加，一位一位的加并加上进位。

# 1 架构面试题

## java

- [1] G1、CMS的使用场景和差异？还了解哪些GC？
- [1] ConcurrentHashMap的实现，还用过哪些JUC的类

- 屏障、信号等的使用场景

- [2] Spring有哪些生成Bean的方式，注解、配置、BeanFactory 
- [3] Feign、cloud-gateway/zuul、Hystrix的架构原理 

- [3] 例如Feign上的Configuration如何生效的 

- [2] 说几个Dubbo的扩展点，用在哪些场景 
- [3] Dubbo怎么和Spring结合的

- 例如怎么把Consumer放到容器中

- [2] Spring Security和Shiro的区别

- [3] Spring Security Oauth的一些用法，怎么实现自定义的认证方式（Grant Type）

- [3] JWT原理 

## 数据库

- [3] 举一个Mysql死锁的场景？怎么排查？怎么解决？

- SQL 

- [3] Mysql Innodb有哪些锁？行锁，间隙锁，next try lock，意向锁等 

- 间隙锁的场景，举个SQL

- [1] Mysql有哪些索引？
- [1] Mysql有哪些引擎   Mysql有哪些引擎 

- [2] 隔离级别有哪些？MVVC怎么支持的这些隔离级别？隔离级别有哪些？MVVC怎么支持的这些隔离级别？
- [4] Undo log和Redo Log的区别Undo log和Redo Log的区别，Redo Log的存在是为了解决什么问题？Redo Log的大小

- [2] Mysql怎么做主从同步的？Mysql怎么做主从同步的？
- [4] 从Mysql的角度考虑主从同步有哪些问题要解决？从Mysql的角度考虑主从同步有哪些问题要解决？

- [1] Mysql哪些情况下不能用到索引（where语句中不包含索引字段）Mysql哪些情况下不能用到索引（where语句中不包含索引字段）
- [3] Mysql排序怎么实现的？

- [4] Mongodb的存储引擎 Mongodb的存储引擎 
-  [2] Mongodb的使用场景？为什么这么用Mongodb的使用场景？为什么这么用

- [2] ES的倒排索引 ES的倒排索引 
- [1] ES的数据模型ES的数据模型

- [2] ES的数据分片怎么配置，有哪些数据类型，ES的数据分片怎么配置，有哪些数据类型，
- [3] 单分片合适的数据量？为什么这么配置 ？怎么调优？单分片合适的数据量？为什么这么配置 ？怎么调优？

- [2]ES支持的查询语法ES支持的查询语法





## Redis

- [2]Redis有哪些数据结构，怎么实现的，例如ZSet的实现

- [4] 跳表还有哪些使用场景？为什么会用跳表？跳表有哪些问题？

- [2] 缓存常见的问题有哪些？击穿、雪崩、穿透等，怎么解决？
- [1] redis还有哪些使用场景？

- [3] redis做分布式锁的注意点

- [3] 缓存和DB的一致性，如何保证？write back，write through

- 例如，为什么更新完数据库，要失效缓存，而不是直接更新？

- [4]Redis的IO模型
- [3]Redis如何做集群，

- [3]一致性Hash算法的原理，如何解决数据分布不均问题



## Mq

- [2]Rabbitmq的消息模型
- [2]如何使用Rabbitmq实现单播和广播消息

- [3]RocketMq/Kafka的底层模型，消息存储，消息同步等

- [4] 延时消息如何实现的
- [5] 事务消息是啥？

- [3]RocketMq/Kafka中如何实现顺序消息



## Zookeeper

- [1] zookeeper有哪些节点类型，使用场景是啥？
- [3] zookeeper的数据同步方式？还知道哪些共识算法？

- [4]简述下这些算法的流程



## 操作系统

- [3] 操作系统的load指标怎么算的？CPU利用率怎么算的？
- [3] IO模型了解哪些？

- [5] I/O多路复用的例子，select, epoll, kqueue

- [1] 网络的七层架构

- [5] 网卡
- [5] iptables

- [1] Linux的常用命令



## 分布式

- [5] 分布式事务有哪些常见实现方式？

- XA
- AT

- TCC
- Saga

- 隔离级别

- [5] 共识算法有哪些？举个工程例子

- zab

- zookeeper

- raft

- nacos
- rocketmq



## 虚拟化

- [4]Docker的原理

- namespace

- [4] K8S的数据模型

- 如何让一个应用的pod尽量分散



## 测试

- [2] 单测中常用的注解和类
- [3] 自动化测试用什么做的

- [3] 性能测试怎么做的，观测指标有哪些？效果是啥？
- [4] 压力测试怎么做的，

- TPS怎么计算？
- 怎么做全链路压测







# 周兴龙面试题

Spring & Spring Boot & Spring Cloud使用

- 注册中心[ZooKeeper、Eureka、Consul 、Nacos等]原理，注册信息同步方式，CAP，监听机制
- 服务治理[Hystrix、Robbin、Feign]熔断原理，Robbin Balancer原理等

- 消息队列

- 引入消息队列的优缺点，项目中使用场景举
- 如何保证消息队列的高可用，源码级说明

- 使用场景说明消息队列消息可靠性传输和保证消息有序性
- 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？有解决过，使用场景说明

- MySQL数据库

- 常用数据引擎有哪些？简述他们的优缺点。
- 简述上述引擎数据结构和使用场景。

- innodb 事务隔离级别有哪些、实现原理及现实场景中使用的那种隔离级别。

- 举SQL说明隔离级别的实现

- SQL优化依据，索引失效场景

- 列举项目中SQL场景

- binlog、undolog和redolog作用及现实使用场景，举例说明
- MySQL执行SQL流程原理，举一个SQL说明

- Redis缓存

- cluster使用场景和数据存储方式。
- Redis 原理模型讲解一下。

- Redis 数据类型有哪些？项目中用了哪些？场景举例说明。
- Redis lur实现原理涉及到哪些算法。

# Java基础知识

## [1]Java 泛型了解么？什么是类型擦除？介绍一下常用的通配符？

Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。**Java 的泛型是伪泛型，这是因为 Java 在编译期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除** **。**

常用的通配符为： T，E，K，V，？

- ？ 表示不确定的 java 类型
- T (type) 表示具体的一个 java 类型

- K V (key value) 分别代表 java 键值中的 Key Value
- E (element) 代表 Element

## [1]==和 equals 的区别

== : 它的作用是判断两个对象的地址是不是相等。(**基本数据类型==比较的是值，引用数据类型==比较的是内存地址**)

equals() : 它的作用也是判断两个对象是否相等，它不能用于比较基本数据类型的变量。**equals()方法存在于Object类中，而Object类是所有类的直接或间接父类**。

equals() 方法存在两种使用情况：

- 情况 1：类没有覆盖 equals()方法。则通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。使用的默认是 Object类equals()方法。
- 情况 2：类覆盖了 equals()方法。一般，我们都覆盖 equals()方法来两个对象的内容相等；若它们的内容相等，则返回 true(即，认为这两个对象相等)。

## [1]为什么要有 hashCode？

减少了 equals 的次数，相应就大大提高了执行速度。因此**equals 方法要被覆盖过，****hashCode****方法也必须被覆盖**

## [1]深拷贝 vs 浅拷贝

- **浅拷贝**：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。
- **深拷贝**：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。

## [1]Java 序列化中如果有些字段不想进行序列化，怎么办？

- 对于不想进行序列化的变量，使用 transient 关键字修饰。
- transient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。transient 只能修饰变量，不能修饰类和方法。

## [1]静态编译和动态编译含义?

- **静态编译：** 在编译时确定类型，绑定对象
- **动态编译：** 运行时确定类型，绑定对象

## [1]反射机制优缺点？

- **优点：** 运行期类型的判断，动态加载类，提高代码灵活度。
- **缺点：**

- 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。
- 安全问题，让我们可以动态操作改变类的属性同时也增加了类的安全隐患。

## [2]反射应用在哪些场景？

- 我们在使用 JDBC 连接数据库时使用 Class.forName()通过反射加载数据库的驱动程序；
- Spring 框架的 IOC（动态加载管理 Bean）创建对象以及 AOP（动态代理）功能都和反射有联系；

- 动态配置实例的属性。

## [2]什么是不受检查异常？有哪些举例说明？

- Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。
- RuntimeException 及其子类都统称为非受检查异常：

- NullPointException
- NumberFormatException（字符串转换为数字）

- ArrayIndexOutOfBoundsException（数组越界）
- ClassCastException（类型转换错误）

- ArithmeticException（算术错误）等。

## [1]种特殊情况下，finally块不会被执行？

- 在 try 或 finally 块中用了 System.exit(int)退出程序。但是，如果 System.exit(int) 在异常语句之后，finally 还是会被执行
- 程序所在的线程死亡。

- 关闭 CPU。

## [1]简述线程、程序、进程的基本概念。以及他们之间关系是什么?

- 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。[**加分项 +1**]与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。
- 程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。

- 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

## [1]线程有哪些基本状态?

  ![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612834526391-c35aaf3b-11b8-466b-8a64-61d7661f520c.png)

- [**加分项 +1**]当线程执行 wait()方法之后，线程进入 WAITING（等待） 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。**如下图**：

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612834568450-ad52518d-193c-4bb3-a584-98d1b91f5cff.png)

## [1]Java 中 IO 流分为几种？

- 按照流的流向分，可以分为输入流和输出流；
- 按照操作单元划分，可以划分为字节流和字符流；

- 按照流的角色划分为节点流和处理流。

## [1]既然有了字节流,为什么还要有字符流?

- 字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。
- **[****加分问题****]不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？**

- 所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。

## [2]BIO,NIO,AIO 有什么区别?

- BIO (Blocking I/O): 同步阻塞 I/O 模式，数据的读取写入必须阻塞在一个线程内等待其完成。[**加分项 +1**]在活动连接数不是特别高（小于单机 1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。
- NIO (Non-blocking/New I/O): NIO 是一种同步非阻塞的 I/O 模型，在 Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。[**加分项 +1**] NIO 提供了与传统 BIO 模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞 I/O 来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发

- AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的 IO 模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。[**加分项 +1**]AIO 是异步 IO 的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO 操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。

## [2]Arrays.asList()将数组转换为集合后可以使用集合方法么？

- 将数组转换为集合后,底层其实还是数组，**Arrays返回的时并没有实现集合的修改方法。使用add、remove等操作方法时会报****UnsupportedOperationException异常**。

## [2]如何将数组转换为ArrayList?

- 【推荐】List list = new ArrayList<>(Arrays.asList("a", "b", "c"))
- **【推荐】**Stream

```
Integer [] myArray = { 1, 2, 3 };
List myList = Arrays.stream(myArray).collect(Collectors.toList());
//基本类型也可以实现转换（依赖boxed的装箱操作）
int [] myArray2 = { 1, 2, 3 };
List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());
```

- 【推荐】Guava

```
对于不可变集合，你可以使用ImmutableList类及其of()与copyOf()工厂方法：（参数不能为空）
List<String> il = ImmutableList.of("string", "elements");  // from varargs
List<String> il = ImmutableList.copyOf(aStringArray);      // from array

对于可变集合，你可以使用Lists类及其newArrayList()工厂方法：
List<String> l1 = Lists.newArrayList(anotherListOrCollection);    // from collection
List<String> l2 = Lists.newArrayList(aStringArray);               // from array
List<String> l3 = Lists.newArrayList("or", "string", "elements"); // from varargs
```

## [2]如何反转数组

```
String [] s= new String[]{
    "dog", "lazy", "a", "over", "jumps", "fox", "brown", "quick", "A"
};
List<String> list = Arrays.asList(s);
Collections.reverse(list);
s=list.toArray(new String[0]);//没有指定类型的话会报错
```

## [2]Java 代理有哪些？《串行》

- **静态代理**

- **含义：**对目标对象的每个方法的增强都是手动完成的。
- **缺点**：不灵活，操作繁琐。

- [**加分项 +1**]代码案例展示

```
定义接口
public interface SmsService {
    String send(String message);
}

实现接口
public class SmsServiceImpl implements SmsService {
    public String send(String message) {
        System.out.println("send message:" + message);
        return message;
    }
}

创建代理类并同样实现接口
public class SmsProxy implements SmsService {

    private final SmsService smsService;

    public SmsProxy(SmsService smsService) {
        this.smsService = smsService;
    }

    @Override
    public String send(String message) {
        //调用方法之前，我们可以添加自己的操作
        System.out.println("before method send()");
        smsService.send(message);
        //调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method send()");
        return null;
    }
}

使用
public class Main {
    public static void main(String[] args) {
        SmsService smsService = new SmsServiceImpl();
        SmsProxy smsProxy = new SmsProxy(smsService);
        smsProxy.send("java");
    }
}
```

## [2]JDK 动态代理和 CGLIB 动态代理对比

- JDK 动态代理只能只能代理实现了接口的类，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
- 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。

- 代码展示[**加分项 +1**]

## [1]ConcurrentHashMap源码+底层数据结构分析

- [**1**]回答基本原理结构
- [**2**]底层数据结构分析

- [**3**]底层数据结构+源码分析

## [1]ArrayList源码+扩容机制分析

- [**1**]回答基本原理结构
- [**2**]扩容机制分析

- [**3**]扩容机制+源码分析

## [2]什么是上下文切换

- 当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。

## [2]什么是线程死锁?如何避免死锁?

- [**1**]多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。
- [2]举例说明或画图展示

```
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}
```

## [2]产生死锁的条件？避免线程死锁?

- 互斥条件：该资源任意一个时刻只由一个线程占用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

- 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

**避免死锁：**

- 破坏以上条件

## [2]为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

- 调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

## [1]说说自己是怎么使用 synchronized 关键字

- synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁。
- synchronized 关键字加到实例方法上是给对象实例上锁。

- 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。

**双重校验锁实现对象单例（线程安全）**

```
public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public  static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。

uniqueInstance 采用 volatile 关键字修饰(建议使用)， uniqueInstance = new Singleton(); 

案例分三步执行：

- 为 uniqueInstance 分配内存空间
- 初始化 uniqueInstance

- 将 uniqueInstance 指向分配的内存地址

## [3]讲一下 synchronized 关键字的底层原理

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612839888024-4922c294-99d2-4b94-ad76-97c009a3d9b2.png)

- synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。
- 当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。

- 在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitor实现的。每个对象中都内置了一个 ObjectMonitor对象。
- 另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

- 在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。
- 在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

总结：

- synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。
- synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。

## [3]谈谈 synchronized 和 ReentrantLock 的区别

- **[****1****]两者都是可重入锁**

- “可重入锁” 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。

- **[****2****]****synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

- synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

- **[****3****]ReentrantLock 比 synchronized 增加了一些高级功能**

- **等待可中断** : ReentrantLock提供了一种能够中断等待锁的线程的机制，通过 lock.lockInterruptibly() 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- **可实现公平锁** : ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

- **可实现选择性通知（锁可以绑定多个条件）**: synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。

- **总结**:使用**ReentrantLock**高级功能会增加额外的性能问题，但一般情况下性能已经不是唯一指标可以忽略

## [1]并发编程的三个重要特性

- 原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized 可以保证代码片段的原子性。
- 可见性 ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。

- 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。

## [1]说说 synchronized 关键字和 volatile 关键字的区别

**[****2****]**synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！

- volatile 关键字是线程同步的轻量级实现，所以**volatile 性能肯定比synchronized关键字要好**。但是**volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块**。
- volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。

- volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。

## [2]ThreadLocal含义及原理

**含义：**

- ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。
- 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（）和 set（）方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

- 实例

```
public class ThreadLocalExample implements Runnable{

     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本
    private static final ThreadLocal<SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyyMMdd HHmm"));

    public static void main(String[] args) throws InterruptedException {
        ThreadLocalExample obj = new ThreadLocalExample();
        for(int i=0 ; i<10; i++){
            Thread t = new Thread(obj, ""+i);
            Thread.sleep(new Random().nextInt(1000));
            t.start();
        }
    }

    @Override
    public void run() {
        System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern());
        try {
            Thread.sleep(new Random().nextInt(1000));
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        //formatter pattern is changed here by thread, but it won't reflect to other threads
        formatter.set(new SimpleDateFormat());

        System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern());
    }
}
```

**ThreadLocal****原理：**

```
public class Thread implements Runnable {
    //与此线程有关的ThreadLocal值。由ThreadLocal类维护
    ThreadLocal.ThreadLocalMap threadLocals = null;

    //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
}
```

- 从上面Thread类 源代码可以看出Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量
- 我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap。

- 默认情况下这两个变量都是 null，只有当前线程调用 ThreadLocal 类的 set或get方法时才创建它们，实际上调用这两个方法的时候，我们调用的是ThreadLocalMap类对应的 get()、set()方法。



- 在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。

- ![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612841128439-ce55d397-3634-44c0-83be-ebe05887aae0.png)

## [2]ThreadLocal 内存泄露问题

ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法

```
static class Entry extends WeakReference<ThreadLocal<?>> {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

## [1]为什么要用线程池？

线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

**使用线程池的好处：**

- 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。

- 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

## [1]实现 Runnable 接口和 Callable 接口的区别

- Runnable 接口不会返回结果或抛出检查异常，但是**Callable 接口**可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。
- 工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。

- Executors.callable（Runnable task或 Executors.callable（Runnable task，Object resule））。

## [2]执行 execute()方法和 submit()方法的区别是什么呢？

- execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；
- submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

## [2]如何创建线程池

- ThreadPoolExecutor创建
- Executors创建【不推荐】

- 原因

- FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
- CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。

## [3]ThreadPoolExecutor 类分析

```
/**
 * 用给定的初始参数创建一个新的ThreadPoolExecutor。
 */
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    if (corePoolSize < 0 ||
        maximumPoolSize <= 0 ||
        maximumPoolSize < corePoolSize ||
        keepAliveTime < 0)
        throw new IllegalArgumentException();
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
```

**[****1****]**只回答以上信息

- ThreadPoolExecutor构造函数重要参数分析
- **最重要的参数：**

- corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。
- maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。

- workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

- **其他常见参数:**

- keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
- unit : keepAliveTime 参数的时间单位。

- threadFactory :executor 创建新线程的时候会用到。
- handler :饱和策略(又名：拒绝策略)。

- **[****3****]ThreadPoolExecutor 饱和策略**

**定义：**当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时执行。

- ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。
- ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。

- ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。
- ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。

- 场景举例：

-  Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。
- 在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 

- 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。

## [3]线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行

- 我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务执行完成后，才会执行剩下的 5 个任务。
- 原理图

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612842585044-7b1755bc-34b9-462d-bb2a-583508502855.png)

## [3]AQS 原理分析

- **[****1****]**AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
- 原理图：

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612842758589-1b20d467-d8d1-410c-b341-cb7a37b40644.png)

AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改；状态信息通过 protected 类型的 getState，setState，compareAndSetState 进行操作

源码：

```
private volatile int state;//共享变量，使用volatile修饰保证线程可见性

//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

## [3]AQS 对资源的共享方式

- Exclusive（独占）：只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁：

- 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
- 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的

- Share（共享）：多个线程可同时执行，如 CountDownLatch、Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

**注意**：ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。

**[****4****]**AQS 底层使用了模板方法模式

- 使用者继承 AbstractQueuedSynchronizer 并重写指定的方法。（这些重写方法很简单，无非是对于共享资源 state 的获取和释放）
- 将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

```
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

## [2]AQS 组件有哪些？

- Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。
- CountDownLatch （倒计时器）： CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。

- CyclicBarrier(循环栅栏)：

-  CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。
- 主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。

- 它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。
- CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

## [2]运行时数据区域

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612843331675-e9b2e8b8-af67-4a9c-967e-a3c357cd76a8.png)    

**线程私有的：**

- 程序计数器
- 虚拟机栈

- 本地方法栈

**线程共享的：**

- 堆
- 方法区

- 直接内存 (非运行时数据区的一部分)

**[****1****]以上回答**

- **[****2****]程序计数器**

- **主要作用:**

1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

- **[****2****]Java 虚拟机栈**

- 与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。
- Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 

- 注意：Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。
- Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。

- **[****1****]****本地方法栈**

- 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。

- **[****1****]****堆**

- 内部分区
- 常用配置参数：

## [2]JVM 内存分配与回收

# 二、中间件

## [3]常用限流算法有哪些？

- **固定窗口计数器算法**

规定我们单位时间处理的请求数量。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612856091779-9aad9bbe-5dc5-4550-9d8a-e22f967fc438.png)

- **滑动窗口计数器算法**

算的上是固定窗口计数器算法的升级版。滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612856106995-a4e0d77d-b079-417a-b8ca-7aae4f9fd0cb.png)

- **漏桶算法**

我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612856188961-e6cfe4dc-3cc5-44a1-9ffb-47cc588d711d.png)

- **令牌桶算法**

令牌桶算法也比较简单。和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1612856257136-e778f9ff-1857-4097-aef8-e427fb6df9e5.png)

## [2]@Transactional注解可以作用于哪些地方？

- @Transactional 可以作用在接口、类、类方法。

- 作用于类：当把@Transactional 注解放在类上时，表示所有该类的public方法都配置相同的事务属性信息。
- 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。

- 作用于接口：不推荐这种使用方法，因为一旦标注在Interface上并且配置了Spring AOP 使用CGLib动态代理，将会导致@Transactional注解失效

```
@Transactional
@RestController
@RequestMapping
publicclass MybatisPlusController {
    @Autowired
    private CityInfoDictMapper cityInfoDictMapper;
    
    @Transactional(rollbackFor = Exception.class)
    @GetMapping("/test")
    public String test() throws Exception {
        CityInfoDict cityInfoDict = new CityInfoDict();
        cityInfoDict.setParentCityId(2);
        cityInfoDict.setCityName("2");
        cityInfoDict.setCityLevel("2");
        cityInfoDict.setCityCode("2");
        int insert = cityInfoDictMapper.insert(cityInfoDict);
        return insert + "";
    }
}
```

## [2]@Transactional注解有哪些属性？

- **propagation属性**

propagation 代表事务的传播行为，默认值为 Propagation.REQUIRED，其他的属性信息如下：

• Propagation.REQUIRED：如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。( 也就是说如果A方法和B方法都添加了注解，在默认传播模式下，A方法内部调用B方法，会把两个方法的事务合并为一个事务 ）

• Propagation.SUPPORTS：如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。

• Propagation.MANDATORY：如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。

• Propagation.REQUIRES_NEW：重新创建一个新的事务，如果当前存在事务，暂停当前的事务。( 当类A中的 a 方法用默认Propagation.REQUIRED模式，类B中的 b方法加上采用 Propagation.REQUIRES_NEW模式，然后在 a 方法中调用 b方法操作数据库，然而 a方法抛出异常后，b方法并没有进行回滚，因为Propagation.REQUIRES_NEW会暂停 a方法的事务 )

• Propagation.NOT_SUPPORTED：以非事务的方式运行，如果当前存在事务，暂停当前的事务。

• Propagation.NEVER：以非事务的方式运行，如果当前存在事务，则抛出异常。

• Propagation.NESTED ：和 Propagation.REQUIRED 效果一样。

- **isolation 属性**

isolation ：事务的隔离级别，默认值为 Isolation.DEFAULT。

• TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.

• TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读

• TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生

• TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

• TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

- **timeout 属性**

- timeout ：事务的超时时间，默认值为 -1。如果超过该时间限制但事务还没有完成，则自动回滚事务。

- **readOnly 属性**

- readOnly ：指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。

- **rollbackFor 属性**

- rollbackFor ：用于指定能够触发事务回滚的异常类型，可以指定多个异常类型。

- **noRollbackFor属性\****

- noRollbackFor：抛出指定的异常类型，不回滚事务，也可以指定多个异常类型。

## [3]@Transactional 注解失效场景

- **@Transactional 应用在非 public 修饰的方法上**

protected、private 修饰的方法上使用 @Transactional 注解，虽然事务无效，但不会有任何报错。

- **@Transactional 注解属性 propagation 设置错误**

- TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
- TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。

- TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。

- **@Transactional  注解属性 rollbackFor 设置错误**

- rollbackFor 可以指定能够触发事务回滚的异常类型。Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定 rollbackFor属性。

- **异常被 catch“吃了”导致@Transactional失效**

## [2]Bean作用域配置

- singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。
- prototype : 每次请求都会创建一个新的 bean 实例。

- request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
- session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。

## **[****1****]@Component,@Repository,@Service, @Controller**

- @Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。
- @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。

- @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
- @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。

## [2]@SpringBootApplication

- @SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。

- @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制
- @ComponentScan： 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描该类所在的包下所有的类。

- @Configuration：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类

# 三、消息队列面试题

## [3]为什么使用消息队列？

- 其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？

- **期望的一个回答**是说，你们公司有个什么**业务场景**，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。

- 先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：**解耦**、**异步**、**削峰**。

#### 解耦

- 看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611972930529-15282a14-2ff6-4ac7-b86f-cfc3404b7715.png)

- 在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！
- 如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611972981151-a5bf9dee-ecdb-42c7-8e34-e10f3cf36ea1.png)

- **总结**：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。
- **面试技巧**：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。

#### 异步

- 再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973088434-a620f459-a785-4991-9c49-051193d9cdab.png)

- 一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。
- 如果**使用 MQ**，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973125573-92abb90b-b8b3-4e08-a8a0-6774d4146938.png)

#### 削峰

- 每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。
- 一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

- 但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973202723-8a4007b4-480f-458f-9e7a-4e904a6d2a61.png)

- 如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973239744-f5628be7-50b1-4273-9691-e9b3bc46f84f.png)

- 这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。

## [3]消息队列有什么优点和缺点？

- 优点上面已经说了，就是**在特殊场景下有其对应的好处**，**解耦**、**异步**、**削峰**。

缺点有以下几个：

- 系统可用性降低

系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？如何保证消息队列的高可用，可以[点击这里查看](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md)。

- 系统复杂度提高

硬生生加个 MQ 进来，你怎么[保证消息没有重复消费](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md)？怎么[处理消息丢失的情况](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md)？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。

- 一致性问题

A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973382750-ad1047fc-c094-42cd-96a5-837b4d787bc3.png)

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 [Apache](https://github.com/apache/rocketmq)，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

## [3]Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？

- 所以**中小型公司**，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；**大型公司**，基础架构研发实力较强，用 RocketMQ 是很好的选择。
- 如果是**大数据领域**的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

## [4]如何保证消息队列的高可用

- 问的是 MQ 的高可用性怎么保证？这样就是你用过哪个 MQ，你就说说你对那个 MQ 的高可用性的理解。

## [2]RabbitMQ 的高可用性

- RabbitMQ 是比较有代表性的，因为是**基于主从**（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。
- RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

#### 单机模式

- 单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的 😄，没人生产用单机模式。

#### 普通集群模式（无高可用性）

- 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你**创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973637914-4a9c1503-f33c-4646-8222-fec74976edef.png)

- 这种方式确实很麻烦，也不怎么好，**没做到所谓的分布式**，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。
- 而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你**开启了消息持久化**，让 RabbitMQ 落地存储消息的话，**消息不一定会丢**，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。

- 所以这个事儿就比较尴尬了，这就**没有什么所谓的高可用性**，**这方案主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作。

#### [3]镜像集群模式（高可用性）

- 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973730621-2b7c8d8b-01d2-41e0-b615-5d419c757ab9.png)

- 那么**如何开启这个镜像集群模式**呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是**镜像集群模式的策略**，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
- 这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就**没有扩展性可言**了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？

## [3]Kafka 的高可用性

- Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。
- 这就是**天然的分布式消息队列**，就是说一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

- 实际上 RabbitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。
- Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。

- 比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973814845-6eab1b0b-0316-49b8-b356-b44069bb60cb.png)

- Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611973848492-8f8fda27-4d2d-4efe-b1bd-08b749b284f4.png)

- 这么搞，就有所谓的**高可用性**了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
- **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

- **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

## [3]RocketMQ的高可用原理

- **RocketMQ的特性**

1. 支持Pub/Sub和P2P两种消息模型
2. 可靠的FIFO队列，**严格保证消息有序**

1. 支持Pull/Push两种消息模式
2. **单一队列百万消息堆积能力**

1. 支持多种消息协议，如JMS
2. **分布式、高可用**

1. Docker镜像云集群部署
2. 功能丰富的Dashboard

- **术语**

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611974278415-a778519a-b628-4d23-be48-9dbe522f7b45.png)

- Producer：生产者将消息发送到队列
- Producer Group：发送同一类消息的生产者组

- Consumer：消费者从队列消费消息
- Consumer Group：消费同一类消息的消费者组

- Topic：**主题是消息的逻辑分类，主要用于区分业务模块，比如购物车、订单……**
- Tag：**标签是对主题的进一步细分，在相同的业务模块内引入标签标记不同用途的消息**

- Message：消息必须指定Topic，可选Tag以便消费端根据Tag过滤消息
- Broker：**相当于MQ，用于接收生产者的消息，存储消息，并为消费者拉取消息做好准备**

- Name Server：**为Producer和Consumer提供路由信息**

- **[****4-5****]高可用架构**

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611974332455-13edfe0d-b37f-4996-8a5f-42cba74b54ca.png)

1. Name Server集群：**提供轻量级的服务发现和路由。每个Name Server记录完整的路由信息，提供等效的读写服务，并支持快速存储扩展。**

1. Name Server之间互不通信，会存在数据不一致的情况。
2. RocketMQ为什么使用Name Server而非ZooKeeper？

1. 因为ZooKeeper为了保证强一致性会放弃一段时间内的可用性，而Name Server作为注册中心只是为了发现组件地址，对一致性要求不高。

1. Broker集群：

1. **提供轻量级的Topic和Queue机制来处理消息存储**；
2. **同时支持Pull/Push模式**；

1. **支持多Master多Slave异步复制/同步双写机制，防止单点故障**；
2. **每一个Master和其Slave之间通过主从复制进行数据同步；**

1. **每个Broker与Name Server集群中的所有节点建立长连接，定时将Topic信息注册到所有Name Server**

1. Producer Group集群：

1. **Producer与Name Server中的任意一个节点建立长连接，定是从Name Server获取Topic路由信息**
2. 请参考ZK或MySQL的集群，凡是涉及到“改数据”的都只会连接Master，即只连接写节点，其他节点只是同步复制Master，这样可以保证数据一致性的实现更简单。

1. **Producer只能和Broker Master建立长连接，定时发送心跳**

1. Consumer Group集群：可以和Broker Master或Broker Slave建立长连接，获取消息；同一个Consumer Group下的多个Consumer**均摊**消费消息，如果设置为**广播**模式，每个Consumer都消费**全量数据**。

- [4]高可用

**1）消息优先级**

**优先级是指在一个MQ中，每条消息都有自己的优先级，一般用整数描述，优先级高的消息先投递（由于MQ采用的是FIFO队列，所以一般是通过将消息按照优先级排序后再发送）。**

对于优先级问题可以归结为两类：

严格的优先级：**优先级用整数表示，投递前按照优先级对消息进行排序，十分耗时**。使用时应该要考虑严格的优先级是否是业务一定需要的，否则不推荐这种。

RocketMQ所有消息都是持久化的，如果按照严格的优先级，对所有消息进行排序，开销会非常大。

非严格意义上的优先级：**将优先级划分为高、中、低，每个优先级用不同的Topic表示，**        `**RocketMQ**`**采用的就是这种方式，单独配置一个高优先级队列和一个低优先级队列，将不同优先级的消息发送到不同队列。**

**2）消息过滤器**

- **Broker端消息过滤**

- 在Broker端，根据Consumer的要求做过滤。
- RocketMQ支持根据Message Tag进行简单的过滤，也支持按照Message Header/Body做过滤

- 优点：**减少了对于Consumer无用消息的网络传输**
- 缺点：**增加了Broker负担，实现相对复杂**

- **Consumer端消息过滤**

在Consumer端进行消息过滤。

- 优点：**可以完全自定义实现**
- 缺点：**会有很多无用消息要传输到Consumer端**

**3）消息持久化**

- MQ通常支持的集中消息持久化方式：

- 持久化到数据库
- 持久化到K/V存储

- **文件记录形式持久化，****如Kafka、RocketMQ**
- 消息持久化部分的性能直接决定了整个消息中间件的性能，RocketMQ充分利用了Linux文件系统内存Cache来提高性能。

- 对内存数据做持久化镜像

**4）消息可靠性**

- 影响消息可靠性的几种情况：

- Broker正常关闭
- Broker异常Crash

- OS Crash
- 机器断点，但是可以恢复

- 以上4种情况都属于硬件资源可恢复的情况，RocketMQ可以通过消息持久化保证消息不丢失，或者只丢失少部分。
- 如果写入磁盘和返回Consumer ACK这两个操作是同步的，那么可以做到消息完全不丢失；如果是异步的，那么会丢失少部分。

同步刷盘怎么才能快？

1.使用DirectBuffer堆外内存，加快内存拷贝；

2.数据和索引分离，通过Offset快速定位，减少I/O随机读写性能损耗

- 机器损坏
- 磁盘损坏

5和6属于单点故障，一旦发生此单点上的消息全部丢失。

RocketMQ通过多Master之间的异步复制保证99%的消息不会丢失，但是仍有少量消息可能丢失。

可以通过同步双写完全避免单点故障，但是同步双写势必影响性能，只适合对消息可靠性要求非常高的情况，比如Money

**5）消息低延迟**

- 消息到达Broker后，在不堆积的情况下，必须要尽快到达Consumer。可以有两种形式：

- Broker Push
- Consumer Pull：RocketMQ采用的是长轮询Pull，可以保证消息实时性

**6）每个消息必须投递至少一次**

- RocketMQ Consumer先将消息Pull到本地，消费完成后，才向服务器返回ACK，可以保证每个消息必须投递至少一次。

**7）每个消息只被处理一次**

这个特性是说：

- 发送消息阶段，不允许发送重复的消息；
- 消费消息阶段，不允许消费重复的消息

- 要在分布式系统中满足以上两点，势必会产生巨大的开销。所以`RocketMQ`为了追求高性能，没有实现此特性，**而是要求业务上进行去重，也就是保证消费消息的幂等性。**

**8）Broker Buffer满了如何处理**

- 通常来说Broker Buffer指的是Broker中一个**队列的内存Buffer大小**，这类Buffer通常大小有限，如果Buffer满了可以有拒绝消息、丢弃队首消息等措施，类似[线程池的拒绝策略](http://www.dragonbaby308.com/multithread/)。
- 但是RocketMQ没有内存Buffer的概念，它的队列都是持久化磁盘，数据定期清除；不过RocketMQ使用LinkedBlockingQueue作为消息队列，理论上是无限大，但是可能导致内存泄漏。

**9）回溯消息**

- 回溯是指Consumer已经消费了的消息，如果业务上需要重新消费，需要支持此功能，RocketMQ的消息都是持久化的，支持通过时间维度进行回溯。

**10）消息堆积**

- 消息堆积在内存Buffer：消息堆积能力取决于内存Buffer大小；
- 消息堆积在持久化存储系统，如磁盘：**当消息不能在内存Cache命中时，要不可避免地访问磁盘，会产生大量的I/O，读I/O的吞吐量直接决定了消息堆积后的访问能力**

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611977273616-be4394ef-69b3-48f6-a34a-9127e0938d75.png)

- RocketMQ采用了一种数据和索引分开的存储方式，有效降低I/O销毁。

**11）分布式事务**

- RocketMQ的分布式事务采用的是二阶段提交（2PA）：

- 2PA在数据存储方面需要KV存储的支持，因为二阶段的提交回滚需要修改消息状态，一定涉及到根据Key查找Message的动作。
- 消息回滚了也不会物理删除，只是逻辑删除

- RocketMQ在二阶段绕过了KV存储，直接在一阶段发送Prepared消息时拿到了消息的地址Offset，二阶段提交回滚时直接通过Offset访问消息，并修改状态。

- 缺点：使用Offset会使得系统的脏页过多。

## [5]如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？

- 回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你先大概说一说可能会有哪些重复消费的问题。
- 首先，比如 RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。

- **[****2****]**Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
- 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

- **[****3****]场景**

- 有这么个场景。数据 1/2/3 依次进入 Kafka，Kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 Kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 offset=153 的这条数据，刚准备去提交 offset 到 Zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，Kafka 也就不知道你已经消费了 offset=153 这条数据。那么重启之后，消费者会找 Kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。
- 注意：新版的 Kafka 已经将 offset 的存储从 Zookeeper 转移至 Kafka brokers，并使用内部位移主题 __consumer_offsets 进行存储。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611977594513-145f0f3e-2270-4392-82af-97210170e3b2.png)

- 如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。
- **[****4****]**其实重复消费不可怕，可怕的是你没考虑到重复消费之后，**怎么保证幂等性**。

- 举个例子吧。假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。

一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。

- 幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，**不能出错**。

- 所以第二个问题来了，怎么保证消息队列消费的幂等性？
- 其实还是得结合业务来思考，我这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。

- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611977652945-5dfa8cc4-ff08-470a-85b1-a26f85312eb2.png)

- 当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。

## [5]如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

- RabbitMQ

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611977759125-82c9b848-05f8-4b95-ad95-f585ac4d770d.png)

- **生产者弄丢了数据**

- 生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。
- 此时可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务 channel.txSelect ，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 channel.txRollback ，然后重试发送消息；如果收到了消息，那么可以提交事务 channel.txCommit 。

```
// 开启事务
channel.txSelect
try {
    // 这里发送消息
} catch (Exception e) {
    channel.txRollback

    // 这里再次重发这条消息
}

// 提交事务
channel.txCommit
```

- 但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能。
- 所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

- 事务机制和 confirm 机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 confirm 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。
- 所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。

- **RabbitMQ 弄丢了数据**
- 就是 RabbitMQ 自己弄丢了数据，这个你必须**开启 RabbitMQ 的持久化**，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。

- 设置持久化有**两个步骤**：

- 创建 queue 的时候将其设置为持久化
- 这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。

- 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2
- 就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

- 必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

- 注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。
- 所以，持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack` ，你也是可以自己重发的。

- **消费端弄丢了数据**

- RabbitMQ 如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。
- 这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack` ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，不就没有 `ack` 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611977963694-e82cfaf3-cfb0-4ea8-8d09-0e1f3b252f89.png)

- Kafka

- **消费端弄丢了数据**

- 唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边**自动提交了 offset**，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。
- 这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

- 生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。

- **Kafka 弄丢了数据**

- 这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。
- 生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。

- 所以此时一般是要求起码设置如下 4 个参数：

- 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。

- 在 producer 端设置 `acks=all` ：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
- 在 producer 端设置 `retries=MAX` （很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

- 我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。

- **生产者会不会弄丢数据？**

- 如果按照上述的思路设置了 `acks=all` ，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

## [4]如何保证消息的顺序性？

- 我们以前做过一个 mysql `binlog` 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -> mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。
- 你在 mysql 里增删改一条数据，对应出来了增删改 3 条 `binlog` 日志，接着这三条 `binlog` 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你愣是换了顺序给执行成删除、修改、增加，不全错了么。

- 本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。
- **[****3****]**先看看顺序会错乱的俩场景：

- **RabbitMQ**：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者 2 先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611978162869-637acd49-d48a-4a3b-ae8b-1a38802848db.png)

- **Kafka**：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。
  消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞**多个线程来并发处理消息**。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611978242367-b2465d14-937e-49a7-b662-c2c1f52c49ec.png)

- **[****4****]****解决方案**

- **RabbitMQ**

- 拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611978313057-85befeb2-e785-4e0f-bb82-8158251cad3e.png)

- **Kafka**

- 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
- 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

![img](https://cdn.nlark.com/yuque/0/2021/png/8382622/1611978397020-c6b0a91d-ae5c-4f9b-b81b-ea791a7058c6.png)

## [5]如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

- **假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。**
- **大量消息在 mq 里积压了几个小时了还没解决**

- 几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。
- 一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。

- 一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。

- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。

- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。

- **mq 中的消息过期失效了**

- 假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是**大量的数据会直接搞丢**。
- 这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是**批量重导**，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。

- 假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

- **mq 都快写满了**

- 如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

- **[****5****]RocketMQ，提供了解决方案。**

**1. 提高消费并行度**

绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法：

同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax 实现。

**2. 批量方式消费**

某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer 的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。

**3. 跳过非重要消息**

发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到 100000 条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下：

```
public ConsumeConcurrentlyStatus consumeMessage(
            List<MessageExt> msgs,
            ConsumeConcurrentlyContext context) {
    long offset = msgs.get(0).getQueueOffset();
    String maxOffset =
            msgs.get(0).getProperty(Message.PROPERTY_MAX_OFFSET);
    long diff = Long.parseLong(maxOffset) - offset;
    if (diff > 100000) {
        // TODO 消息堆积情况的特殊处理
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    }
    // TODO 正常消费过程
    return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
```

**4. 优化每条消息消费过程**

举例如下，某条消息的消费过程如下：

- 根据消息从 DB 查询【数据 1】
- 根据消息从 DB 查询【数据 2】

- 复杂的业务计算
- 向 DB 插入【数据 3】

- 向 DB 插入【数据 4】

这条消息的消费过程中有 4 次与 DB 的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把 DB 部署在 SSD 硬盘，相比于 SCSI 磁盘，前者的 RT 会小很多。

## [5]如果让你写一个消息队列，该如何进行架构设计？说一下你的思路。

- 知道那个技术的基本原理、核心组成部分、基本架构构成串起来即可。
- 比如说这个消息队列系统，我们从以下几个角度来考虑一下：

- 首先这个 mq 得支持可伸缩性，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的数据要不要落地磁盘？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。

- 其次你考虑一下你的 mq 的可用性？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
- 能不能支持数据 0 丢失？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

- mq 肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。
- 



